name: Data Validation Tests

on:
  # Manual trigger with parameters
  workflow_dispatch:
    inputs:
      query_type:
        description: 'Query type to run'
        required: true
        type: choice
        options:
          - count
          - except_distinct
          - except_distinct_fullload
          - except_distinct_deltaload
          - schema_compare
        default: 'count'
      tablename:
        description: 'Table name filter (e.g., rcti_c* or *)'
        required: false
        default: '*'
        type: string
      project:
        description: 'GCP Project ID (PRD)'
        required: false
        default: 'ncau-data-newsquery-prd'
        type: string
      project_nq:
        description: 'GCP Project ID (NQ/SIT)'
        required: false
        default: 'ncau-data-newsquery-sit'
        type: string
      dataset:
        description: 'Dataset name (PRD)'
        required: false
        default: 'sdm_rcti'
        type: string
      dataset_nq:
        description: 'Dataset name (NQ/SIT)'
        required: false
        default: 'sdm_rcti'
        type: string
      startdate:
        description: 'Start date PRD (YYYY-MM-DD)'
        required: false
        default: ''
        type: string
      enddate:
        description: 'End date PRD (YYYY-MM-DD)'
        required: false
        default: ''
        type: string
      startdate_nq:
        description: 'Start date NQ/SIT (YYYY-MM-DD)'
        required: false
        default: ''
        type: string
      enddate_nq:
        description: 'End date NQ/SIT (YYYY-MM-DD)'
        required: false
        default: ''
        type: string
  
  # Auto trigger on push to main
  push:
    branches:
      - main
    paths:
      - 'features/**'
      - 'sqls/**'
      - 'src/**'
      - 'config/**'
  
  # Scheduled runs
  schedule:
    - cron: '0 2 * * *'  # Daily at 2 AM UTC

env:
  GCP_PROJECT_ID: ncau-data-newsquery-sit
  RESULTS_BUCKET: ncau-validation-results

jobs:
  validate-data:
    name: Run ${{ github.event.inputs.query_type || 'count' }} Validation
    runs-on: ubuntu-latest
    timeout-minutes: 60
    
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python 3.10
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'
          cache: 'pip'

      - name: Set up Java 17
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '17'

      - name: Install Python dependencies
        run: |
          pip install --upgrade pip
          pip install -r requirements.txt

      - name: Authenticate to Google Cloud
        uses: google-github-actions/auth@v2
        with:
          credentials_json: ${{ secrets.GCP_SA_KEY }}

      - name: Set up Cloud SDK
        uses: google-github-actions/setup-gcloud@v2

      - name: Update config with user inputs
        if: github.event_name == 'workflow_dispatch'
        run: |
          python << 'EOF'
          import yaml
          
          with open('config/config.yaml', 'r') as f:
              config = yaml.safe_load(f)
          
          # Update with workflow inputs if provided
          config['project'] = '${{ github.event.inputs.project }}' or config.get('project')
          config['project_nq'] = '${{ github.event.inputs.project_nq }}' or config.get('project_nq')
          config['dataset'] = '${{ github.event.inputs.dataset }}' or config.get('dataset')
          config['dataset_nq'] = '${{ github.event.inputs.dataset_nq }}' or config.get('dataset_nq')
          config['startdate'] = '${{ github.event.inputs.startdate }}' or config.get('startdate')
          config['enddate'] = '${{ github.event.inputs.enddate }}' or config.get('enddate')
          config['startdate_nq'] = '${{ github.event.inputs.startdate_nq }}' or config.get('startdate_nq')
          config['enddate_nq'] = '${{ github.event.inputs.enddate_nq }}' or config.get('enddate_nq')
          
          with open('config/config.yaml', 'w') as f:
              yaml.dump(config, f, default_flow_style=False)
          
          print("Updated config:")
          print(yaml.dump(config, default_flow_style=False))
          EOF

      - name: Verify BigQuery connection
        run: |
          bq ls ${{ env.GCP_PROJECT_ID }}:sdm_rcti_nq

      - name: Run Karate Tests
        id: run-tests
        run: |
          QUERY_TYPE="${{ github.event.inputs.query_type || 'count' }}"
          TABLENAME="${{ github.event.inputs.tablename || '*' }}"
          
          echo "Running $QUERY_TYPE tests with table filter: $TABLENAME"
          
          java -Dtablename="$TABLENAME" \
               -jar karate-1.5.1.jar \
               --tags @regression \
               features/test_${QUERY_TYPE}.feature
        continue-on-error: true

      - name: Check for test failures
        id: check-failures
        run: |
          if [ -d "output/failed_testcases" ] && [ "$(ls -A output/failed_testcases)" ]; then
            echo "has_failures=true" >> $GITHUB_OUTPUT
            FAILED_COUNT=$(ls -1 output/failed_testcases/*.sql 2>/dev/null | wc -l)
            echo "failed_count=$FAILED_COUNT" >> $GITHUB_OUTPUT
          else
            echo "has_failures=false" >> $GITHUB_OUTPUT
            echo "failed_count=0" >> $GITHUB_OUTPUT
          fi

      - name: Upload test results and logs
        if: always()
        uses: actions/upload-artifact@v4
        with:
          name: test-results-${{ github.run_number }}
          path: |
            output/
            target/karate-reports/
            logs/
          retention-days: 30

      - name: Upload to GCS (optional)
        if: false # Disabled - bucket not created yet
        run: |
          gsutil -m cp -r output/ gs://${{ env.RESULTS_BUCKET }}/results/${{ github.run_number }}/
          gsutil -m cp -r target/karate-reports/ gs://${{ env.RESULTS_BUCKET }}/reports/${{ github.run_number }}/

      - name: Generate test summary
        if: always()
        run: |
          # Read actual config values used
          python << 'PYEOF'
          import yaml
          with open('config/config.yaml', 'r') as f:
              config = yaml.safe_load(f)
          
          print(f"CONFIG_PROJECT={config.get('project', 'N/A')}")
          print(f"CONFIG_PROJECT_NQ={config.get('project_nq', 'N/A')}")
          print(f"CONFIG_DATASET={config.get('dataset', 'N/A')}")
          print(f"CONFIG_DATASET_NQ={config.get('dataset_nq', 'N/A')}")
          print(f"CONFIG_STARTDATE={config.get('startdate', 'N/A')}")
          print(f"CONFIG_ENDDATE={config.get('enddate', 'N/A')}")
          print(f"CONFIG_STARTDATE_NQ={config.get('startdate_nq', 'N/A')}")
          print(f"CONFIG_ENDDATE_NQ={config.get('enddate_nq', 'N/A')}")
          PYEOF
          
          # Read config into environment
          eval $(python << 'PYEOF'
          import yaml
          with open('config/config.yaml', 'r') as f:
              config = yaml.safe_load(f)
          print(f"export CONFIG_PROJECT='{config.get('project', 'N/A')}'")
          print(f"export CONFIG_PROJECT_NQ='{config.get('project_nq', 'N/A')}'")
          print(f"export CONFIG_DATASET='{config.get('dataset', 'N/A')}'")
          print(f"export CONFIG_DATASET_NQ='{config.get('dataset_nq', 'N/A')}'")
          print(f"export CONFIG_STARTDATE='{config.get('startdate', 'N/A')}'")
          print(f"export CONFIG_ENDDATE='{config.get('enddate', 'N/A')}'")
          print(f"export CONFIG_STARTDATE_NQ='{config.get('startdate_nq', 'N/A')}'")
          print(f"export CONFIG_ENDDATE_NQ='{config.get('enddate_nq', 'N/A')}'")
          PYEOF
          )
          
          echo "## Test Execution Summary" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Query Type:** ${{ github.event.inputs.query_type || 'count' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Table Filter:** ${{ github.event.inputs.tablename || '*' }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Project (PRD):** $CONFIG_PROJECT" >> $GITHUB_STEP_SUMMARY
          echo "- **Project (NQ):** $CONFIG_PROJECT_NQ" >> $GITHUB_STEP_SUMMARY
          echo "- **Dataset (PRD):** $CONFIG_DATASET" >> $GITHUB_STEP_SUMMARY
          echo "- **Dataset (NQ):** $CONFIG_DATASET_NQ" >> $GITHUB_STEP_SUMMARY
          echo "- **Date Range (PRD):** $CONFIG_STARTDATE to $CONFIG_ENDDATE" >> $GITHUB_STEP_SUMMARY
          echo "- **Date Range (NQ):** $CONFIG_STARTDATE_NQ to $CONFIG_ENDDATE_NQ" >> $GITHUB_STEP_SUMMARY
          echo "- **Failed Tests:** ${{ steps.check-failures.outputs.failed_count }}" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          
          if [ "${{ steps.check-failures.outputs.has_failures }}" == "true" ]; then
            echo "### ❌ Failed Test Cases:" >> $GITHUB_STEP_SUMMARY
            for file in output/failed_testcases/*.sql; do
              [ -e "$file" ] || continue
              echo "- $(basename $file .sql)" >> $GITHUB_STEP_SUMMARY
            done
          else
            echo "### ✅ All tests passed!" >> $GITHUB_STEP_SUMMARY
          fi
          
      - name: Fail job if tests failed
        if: steps.check-failures.outputs.has_failures == 'true'
        run: |
          echo "::error::${{ steps.check-failures.outputs.failed_count }} test(s) failed"
          exit 1